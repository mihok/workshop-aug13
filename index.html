<!DOCTYPE html>
<html lang="en" style="height:100%">

<head>
    <meta charSet="UTF-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="description" content="Artificial intelligence with Mihok from TorontoJS, building on basic knowledge we will discover and build Neural Networks from scratch to get a better understanding of how they work." />
    <title>JS Workshop</title>
    <script type="text/javascript" src="helpers/manifest.lib.js"></script>
    <script type="text/javascript" src="helpers/math.lib.js"></script>
    <script type="text/javascript" src="helpers/data.lib.js"></script>
    <!-- Insert Live Editor here -->
</head>

<body>
  <script type="text/javascript" src="helpers/renderers.lib.js"></script>
  <script type="text/javascript">


// Shared variable names to reference information
const H1 = 0 // Hidden Layer Neuron #1
const H2 = 1 // Hidden Layer Neuron #2
const O1 = 2 // Output Layer #1

const W1 = 0;
const W2 = 1;
const W3 = 2;
const W4 = 3;
const W5 = 4;
const W6 = 5;

const I1 = 0;
const I2 = 1;

// Our neural network muhaahaahaahaaaa
class Network {

  // The network's fields

  // Our biases
  biases = [
    0, // b1 (hidden1)
    0, // b2 (hidden2)
    0, // b3 (output)
  ];

  // Our weights (w1 to w6)
  weights = [0, 0, 0, 0, 0, 0];
  
  lossFn = function (a, p) { throw new Error('not implemented'); };
  
  hidden = [];
  output;

  constructor (weights = [], bias = [], activateFn, derivFn, lossFn) {
    this.biases = bias;
    this.weights = weights;
    
    this.lossFn = lossFn;

    const h1Weights = [ this.weights[W1], this.weights[W2] ];
    const h2Weights = [ this.weights[W3], this.weights[W4] ];
    const o1Weights = [ this.weights[W5], this.weights[W6] ];

    // Define our hidden input layers
    this.hidden = [
      new Neuron(h1Weights, this.biases[H1], activateFn, derivFn),
      new Neuron(h2Weights, this.biases[H2], activateFn, derivFn),
    ];

    // Define our output neuron, we assume only one output no matter what
    this.output = new Neuron(o1Weights, this.biases[O1], activateFn, derivFn);
  }

  // train() takes in a set of data to train on, and corrisponding answers 
  train (data = [], answers = [], iterations = 1000, rate = 0.1) {
    let lossData = [];

    // We'll iterate over the data several times to adjust the weights 
    for (let i = 0; i < iterations; i += 1) {
      for (let d in data) {
        // Get our individual neuron data to calculate things

        // Calculate our 1st hidden layer neuron
        let h1Sum = this.hidden[H1].sum(data[d]);
        let h1 = this.hidden[H1].activatorFn(h1Sum);

        // Calculate our 2nd hidden layer neuron
        let h2Sum = this.hidden[H2].sum(data[d]);
        let h2 = this.hidden[H2].activatorFn(h2Sum);

        // Calcualte our output layer neuron
        let o1Sum = this.output.sum([h1, h2]);
        let o1 = this.output.activatorFn(o1Sum);

        // Here is the networks current prediction
        let pred = o1;


        // Now we'll calculate an adjustment to the weights with partial
        // derivatives to improve that prediction based on the actual answers.
        // The formula we use is the following,
        //
        // ∂L/∂wN = ∂L/∂pred * ∂pred/∂wN
        //
        // Which will give us a value that we can apply against our learning
        // rate to adjust a particular weight
        
        // ∂L/∂pred = -2*(answer - prediction);
        let pLpO1 = -2 * (answers[d] - pred);


        // Lets do our backpropagation to calculate the rest

        // Output Neuron

        // ∂pred/∂w6
        let pO1pW6 = h1 * Math.derivSigmoid(o1Sum);
        // ∂pred/∂w5
        let pO1pW5 = h2 * Math.derivSigmoid(o1Sum);

        // ∂pred/∂b3
        let pO1pB3 = Math.derivSigmoid(o1Sum);


        // ∂pred/∂h1
        let pO1pH1 = this.weights[W5] * Math.derivSigmoid(o1Sum);
        // ∂pred/∂h2
        let pO1pH2 = this.weights[W6] * Math.derivSigmoid(o1Sum);

        // Hidden Neurons

        // ∂h1/∂w1
        let pH1pW1 = data[d][I1] * Math.derivSigmoid(h1Sum);
        // ∂h2/w2
        let pH1pW2 = data[d][I2] * Math.derivSigmoid(h1Sum);
        // ∂h1/b1
        let pH1pB1 = Math.derivSigmoid(h1Sum);

        // ∂h2/w3
        let pH2pW3 = data[d][I1] * Math.derivSigmoid(h2Sum);
        // ∂h2/w4
        let pH2pW4 = data[d][I2] * Math.derivSigmoid(h2Sum);
        // ∂h2/b2
        let pH2pB2 = Math.derivSigmoid(h2Sum);


        // Set our new weights and biases in our network so we remember them
        this.weights[W1] -= rate * pLpO1 * pO1pH1 * pH1pW1;
        this.weights[W2] -= rate * pLpO1 * pO1pH1 * pH1pW2;
       
        this.weights[W3] -= rate * pLpO1 * pO1pH2 * pH2pW3;
        this.weights[W4] -= rate * pLpO1 * pO1pH2 * pH2pW3;
       
        this.weights[W5] -= rate * pLpO1 * pO1pW5;
        this.weights[W6] -= rate * pLpO1 * pO1pW6;

        this.biases[H1] -= rate * pLpO1 * pO1pH1 * pH1pB1;
        this.biases[H2] -= rate * pLpO1 * pO1pH2 * pH2pB2;
        this.biases[O1] -= rate * pLpO1 * pO1pB3;


        // Now let's update our weights and biases to minimize loss
        
        // Output Neuron
        // Update our ouput neuron to reflect the new weights
        this.output.weights = [
          this.weights[W5],
          this.weights[W6],
        ];

        this.output.bias = this.biases[O1];


        // Hidden Layer Neuron #2
        // Update our neuron to reflect the new weights
        this.hidden[H2].weights = [
          this.weights[W3],
          this.weights[W4],
        ];

        this.hidden[H2].bias = this.biases[H2];

        // Hidden Layer Neuron #1
        // Update our neuron to reflect the new weights
        this.hidden[H1].weights = [
          this.weights[W1],
          this.weights[W2],
        ];

        this.hidden[H1].bias = this.biases[H1];
      }

      // Finally lets calculate our loss and output it for sanity
      if (i % 10 === 0) {
        // Generate an array of the output of our network at this time for each
        // row of data, then 
        let currentPrediction = [];
        data.forEach((row) => {
          currentPrediction.push(this.query(row));
        }, this);
        let loss = this.lossFn(answers, currentPrediction);

        lossData.push(loss);

        console.log(`iteration #${i}, loss: ${loss}`);
      }
    }

    console.graph(lossData);
  }

  // run() takes in inputs for a single run of the network, typically done after
  // it has been trained
  query (inputs = []) {
    let params = [];

    for (let h in this.hidden) {
      params.push(this.hidden[h].activate(inputs));
    }

    return this.output.activate(params);
  }
}

// Our quintessential neuron! huzah!
class Neuron {

  // The neuron fields
  bias;
  weights;
  activatorFn = function (x) { throw new Error('not implemented'); };
  derivFn = function (x) { throw new Error('not implemented'); };

  constructor (weights = [], bias = 0, activateFn, derivFn) {
    this.bias = bias;
    this.weights = weights;
    this.activatorFn = activateFn;
    this.derivFn = derivFn;
  }

  sum (inputs = []) {
    let buffer = [];
    let output = 0;

    // Multiply the weights against the inputs
    for (let i in inputs) {
        buffer[i] = inputs[i] * this.weights[i];
    }

    // Add them all up
    for (let b in buffer) {
        output += buffer[b];
    }
    
    // Finally add our bias
    output += this.bias

    return output;
  }

  activate (inputs = []) {
    if (inputs.length !== this.weights.length) {
      throw new Error('input and weight shape mismatch');
    }
   
    let output = 0;

    output = this.sum(inputs);
    
    // Activate the neuron (or not), based on applying the sigmoid function
    // to the output of our inputs, weights, and biases.
    let result = this.activatorFn(output);
    
    return result;
  }
}

// const w = [0, 1];
// const b = 0;

// const nn = new Network(w, b, Math.sigmoid);

// const x = [2, 3];
// console.log('Run neural network against inputs');
// console.log(nn.run(x));


// Let's generate our training data in a machine-readable form
const data = [];

for (let row in DATA.whg) {
  data.push([
    // I1
    DATA.whg[row].weight,
    // I2
    DATA.whg[row].height,
  ]);
};

// Let's generate our training "answer" data in a machine-readable form
const answers = [];
for (let row in DATA.whg) {
  answers.push(DATA.whg[row].gender);
}


console.log('Create neural network');
const nn = new Network(
  // weights
  [1, 1, 1, 1, 1, 1],
  // bias
  [0, 0, 0],
  // activation function
  Math.sigmoid,
  // derivitave function of our activation function
  Math.derivSigmoid,
  // loss function
  Math.meanSquaredError,
);

console.log('Train neural network', data, answers);
nn.train(data, answers, 1000, 0.1)

console.log('Is Emily ( a girl or a boy')
console.log('Answer', nn.query([-7, -3]));

console.log('Is Frank a girl or a boy')
console.log('Answer', nn.query([20, 2]));

  </script>
</body>

</html>
